{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title",
   "metadata": {},
   "source": [
    "# 02 ‚Äî Preprocessing & Feature Engineering\n",
    "\n",
    "> **Objective:** To implement the cleaning and feature-engineering steps used in the overqualification pipeline: handling NGS special codes, normalizing mixed-type columns, and preparing categorical features for CatBoost.\n",
    "\n",
    "This notebook covers:\n",
    "1. [**Preprocessing**](#preprocessing) ‚Äî `clean()`: missing codes and categorical normalization  \n",
    "2. [**Feature engineering**](#feature-engineering) ‚Äî `add_features()`: categorical encoding for CatBoost  \n",
    "3. [**Before/after comparison**](#before-and-after-comparison) ‚Äî data shape and sample values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "context",
   "metadata": {},
   "source": [
    "### üß† Context\n",
    "\n",
    "The NGS dataset uses **6, 9, 99** as valid skip / refused / not stated. The pipeline treats these as missing and fills them consistently. Columns such as **GENDER2**, **DDIS_FL**, and **VISBMINP** sometimes contain text (e.g. \"Female\", \"With disability\") in addition to numeric codes; we normalize these to numeric codes before converting to categorical strings for CatBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports",
   "metadata": {},
   "source": [
    "---\n",
    "### üß∞ Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.insert(0, str(Path().resolve().parent))\n",
    "\n",
    "from src.data import load_train\n",
    "from src.preprocess import clean\n",
    "from src.features import add_features, get_categorical_feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load",
   "metadata": {},
   "source": [
    "### üì• Load raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = load_train()\n",
    "print(\"Shape:\", df_raw.shape)\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preprocessing",
   "metadata": {},
   "source": [
    "### üßπ Preprocessing <a id=\"preprocessing\"></a>\n",
    "\n",
    "`clean()`:\n",
    "- Replaces NGS codes **6, 9, 99** with `NaN` in numeric/code columns  \n",
    "- Normalizes **GENDER2** (e.g. \"Male\" ‚Üí 1, \"Female\" ‚Üí 2)  \n",
    "- Normalizes **DDIS_FL** (\"With disability\" / \"Without disability\")  \n",
    "- Normalizes **VISBMINP** (e.g. \"Yes\" / \"No\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clean-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = clean(df_raw)\n",
    "print(\"After clean():\")\n",
    "print(\"  GENDER2 sample values:\", df_cleaned[\"GENDER2\"].dropna().astype(str).unique()[:8])\n",
    "print(\"  DDIS_FL sample values:\", df_cleaned[\"DDIS_FL\"].dropna().astype(str).unique()[:8])\n",
    "print(\"  Null count (should increase where 6/9/99 were replaced):\", df_cleaned.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feature-eng",
   "metadata": {},
   "source": [
    "### üîß Feature Engineering <a id=\"feature-engineering\"></a>\n",
    "\n",
    "`add_features()`:\n",
    "- Converts all survey-code columns to **string** type (CatBoost treats object columns as categorical)  \n",
    "- Fills remaining NaN in those columns with the string `\"missing\"` so CatBoost can use them as a category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add-features-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_engineered = add_features(df_cleaned)\n",
    "cat_cols = get_categorical_feature_names()\n",
    "print(\"Categorical feature names (for CatBoost):\", cat_cols)\n",
    "print(\"\\nSample of engineered columns (string type):\")\n",
    "print(df_engineered[cat_cols[:5]].dtypes)\n",
    "print(\n",
    "    \"\\nUnique values in CERTLEVP (after add_features):\",\n",
    "    df_engineered[\"CERTLEVP\"].astype(str).unique()[:10],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "before-after",
   "metadata": {},
   "source": [
    "### üìä Before and After Comparison <a id=\"before-and-after-comparison\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compare-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Raw shape:\", df_raw.shape)\n",
    "print(\"After clean + add_features:\", df_engineered.shape)\n",
    "print(\"\\nNo rows/columns dropped; only types and values normalized.\")\n",
    "print(\"\\nPipeline order: load_train() ‚Üí clean() ‚Üí add_features() ‚Üí split_X_y() for model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "---\n",
    "## üìù Summary\n",
    "\n",
    "Preprocessing and feature engineering produce a single DataFrame that retains `id` and `overqualified` and has all predictor columns as **string-typed categories** suitable for CatBoost. The same sequence is used in `src/train.py` and `src/predict.py`.\n",
    "\n",
    "**Next step:** `03_catboost_training_tuning.ipynb` ‚Äî train and tune the CatBoost model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
